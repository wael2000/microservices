<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Modern Web Applications on OpenShift: Part 1 – Web apps in two commands</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/klACS25fJiI/" /><category term="JavaScript" /><category term="Node.js" /><category term="Red Hat OpenShift Application Runtimes" /><category term="Red Hat OpenShift Container Platform" /><category term="angular" /><category term="Javascript" /><category term="OpenShift Enterprise by Red Hat" /><category term="react" /><category term="Red Hat OpenShift" /><category term="S2I" /><author><name>Lucas Holmquist</name></author><id>https://developers.redhat.com/blog/?p=516177</id><updated>2018-10-04T17:00:23Z</updated><published>2018-10-04T17:00:23Z</published><content type="html">&lt;p&gt;In this multi-part series, we will take a look at how to deploy modern web applications, like React and Angular apps, to &lt;a href="http://openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt; using a new source-to-image (S2I) builder image.&lt;/p&gt; &lt;p&gt;This first post will cover how to deploy modern web apps using the fewest steps.&lt;/p&gt; &lt;p&gt;The next post will show how to combine this new S2I image with a current HTTP server image, like NGINX, using an OpenShift chained build for a more production-ready deployment.&lt;/p&gt; &lt;p&gt;The last post will show how to run your app&amp;#8217;s development server on OpenShift while syncing with your local file system.&lt;/p&gt; &lt;p&gt;&lt;span id="more-516177"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Some initial setup&lt;/h2&gt; &lt;p&gt;If you want to follow along, there are some prerequisites. You&amp;#8217;ll need a running instance of OpenShift. I&amp;#8217;ll be using minishift which allows you to run OpenShift on your Windows, Mac, or Linux desktop in a VM. To get minishift, download &lt;a href="https://developers.redhat.com/products/cdk/overview/"&gt;Red Hat Container Development Kit (CDK)&lt;/a&gt;.  Follow&lt;a href="https://developers.redhat.com/products/cdk/hello-world/"&gt; these instructions&lt;/a&gt; to install and getting minishift running. For more information see the &lt;a href="https://developers.redhat.com/products/cdk/docs-and-apis/"&gt;CDK documentation&lt;/a&gt;, and the &lt;a href="https://docs.okd.io/latest/minishift/index.html"&gt;documentation on OKD.io&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once minishift is running, you need to make sure you are logged in and have a project set up, which you can do using code like this:&lt;/p&gt; &lt;pre&gt;$ oc login $ oc new-project web-apps &lt;/pre&gt; &lt;p&gt;I also assume you have Node.js 8+ and npm 5.2+ installed.&lt;/p&gt; &lt;p&gt;If all you want to see are the two commands, skip to the &amp;#8220;Summary&amp;#8221; section.&lt;/p&gt; &lt;h2&gt;What is a modern web application?&lt;/h2&gt; &lt;p&gt;Before we begin, we should probably define what exactly a modern web application is and how it differs from what I like to call a &amp;#8220;pure&amp;#8221; Node.js application.&lt;/p&gt; &lt;p&gt;To me, a modern web application is something like React, Angular, or Ember, where there is a build step that produces static HTML, JavaScript, and CSS. This build step usually does a few different tasks, like concatenation, transpilation (Babel or Typescript), and minifying of the files. Each of the major frameworks has its own build process and pipeline, but tools like Webpack, Grunt, and Gulp also fall into this category. No matter what tool is used, they all use Node.js to run the build processes.&lt;/p&gt; &lt;p&gt;But the static content that is generated (compiled) doesn&amp;#8217;t necessarily need a node process to serve it. Yes, you could use something like the &lt;a href="https://www.npmjs.com/package/serve"&gt;serve module&lt;/a&gt;, which is nice for development since you can see your site quickly, but for production deployments, it is usually recommend to use something like NGINX or Apache HTTP Server.&lt;/p&gt; &lt;p&gt;A &amp;#8220;pure&amp;#8221; node application, on the other hand, will use a Node.js process to run and can be something like an &lt;a href="http://expressjs.com/"&gt;Express.js application&lt;/a&gt; (that is, a REST API server), and there isn&amp;#8217;t usually a build step (I know, I know: Typescript is a thing now). Development dependencies are usually not installed since we only want the dependencies that the app uses to run.&lt;/p&gt; &lt;p&gt;To see an example of deploying a &amp;#8220;pure&amp;#8221; node app to OpenShift quickly using our Node.js S2I image, check out my post on &lt;a href="https://developers.redhat.com/blog/2018/04/16/zero-express-openshift-3-commands/"&gt;deploying an Express.js application to OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Deploying a web app to OpenShift&lt;/h2&gt; &lt;p&gt;Now that we understand the difference between a modern web application and a Node.js application, let&amp;#8217;s see how we go about getting our web app on OpenShift.&lt;/p&gt; &lt;p&gt;For this post, we will deploy both a React and a modern Angular application. We can create both projects pretty quickly using their respective CLI tools, &lt;code&gt;create-react-app&lt;/code&gt; and&lt;code&gt; @angular/cli.&lt;/code&gt; This will count as one of the two commands I referred to in the title.&lt;/p&gt; &lt;h3&gt;React App&lt;/h3&gt; &lt;p&gt;Let&amp;#8217;s start with the React application. If you have &lt;code&gt;create-react-app&lt;/code&gt; installed globally, great. But if not, then you can run the command using &lt;code&gt;npx&lt;/code&gt; like this:&lt;/p&gt; &lt;pre&gt;$ npx create-react-app react-web-app &lt;/pre&gt; &lt;p&gt;&lt;i&gt;Note: npx is a tool that comes with npm 5.2+ to run one-off commands. Check out &lt;a href="https://www.npmjs.com/package/npx"&gt;more here&lt;/a&gt;.&lt;/i&gt;&lt;/p&gt; &lt;p&gt;This command will create a new React app, and you should see something like this:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success.png"&gt;&lt;img class=" aligncenter wp-image-521627 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success-1024x353.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success-1024x353.png" alt="Screenshot of what you see after successfully creating a React app" width="640" height="221" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success-1024x353.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success-300x104.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success-768x265.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/create-react-app-success.png 1405w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Assuming you are in the newly created project directory, you can now run the second command to deploy the app to OpenShift:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --strictSSL=false --dockerImage=bucharestgold/centos7-s2i-web-app --imageTag=10.x --build.env YARN_ENABLED=true --expose &lt;/pre&gt; &lt;p&gt;Your OpenShift web console will look something like this:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running.png"&gt;&lt;img class=" aligncenter wp-image-521727 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running-1024x523.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running-1024x523.png" alt="Screenshot of OpenShift web console after deploying the React app" width="640" height="327" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running-1024x523.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running-300x153.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-quick-running-768x392.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And here&amp;#8217;s what the web console looks like when you run the application:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift.png"&gt;&lt;img class=" aligncenter wp-image-521737 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift-1024x566.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift-1024x566.png" alt="Screenshot of what the web console looks like when you run the React app" width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift-1024x566.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift-768x424.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/react-on-openshift.png 1453w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Before we get into the Angular example, let&amp;#8217;s see what that last command was doing.&lt;/p&gt; &lt;p&gt;First, we see &lt;code&gt;npx nodeshift&lt;/code&gt;. We are using npx to run the nodeshift module. As I&amp;#8217;ve mentioned in previous posts, &lt;a href="https://www.npmjs.com/package/nodeshift"&gt;nodeshift&lt;/a&gt; is a module for easily deploying node apps to OpenShift.&lt;/p&gt; &lt;p&gt;Next, let&amp;#8217;s see what options are being passed to nodeshift. The first is &lt;code&gt;--strictSSL=false&lt;/code&gt;. Since we are using minishift, which is using a self-signed certificate, we need to tell nodeshift (really, we are telling the request library, which is used under the covers), about this so a security error isn&amp;#8217;t thrown.&lt;/p&gt; &lt;p&gt;Next is &lt;code&gt;--dockerImage=bucharestgold/centos7-s2i-web-app --imageTag=10.x&lt;/code&gt;. This tells nodeshift we want to use the new &lt;a href="https://hub.docker.com/r/bucharestgold/centos7-s2i-web-app/"&gt;Web App Builder image&lt;/a&gt; and we want to use its 10.x tag.&lt;/p&gt; &lt;p&gt;Next, we want to tell the S2I image that we want to use yarn: &lt;code&gt;--build.env YARN_ENABLED=true&lt;/code&gt;. And finally, the &lt;code&gt;--expose&lt;/code&gt; flag tells nodeshift to create an OpenShift route for us, so we can get a publicly available link to our application.&lt;/p&gt; &lt;p&gt;Since this is a &amp;#8220;get on OpenShift quickly&amp;#8221; post, the S2I image uses the &lt;a href="https://www.npmjs.com/package/serve"&gt;serve module&lt;/a&gt; to serve the generated static files. In a later post, we will see how to use this S2I image with NGINX.&lt;/p&gt; &lt;h3&gt;Angular App&lt;/h3&gt; &lt;p&gt;Now let&amp;#8217;s create an Angular application. First, we need to create our new application using the Angular CLI. Again, if you don&amp;#8217;t have it installed globally, you can run it with npx:&lt;/p&gt; &lt;pre&gt;$ npx @angular/cli new angular-web-app &lt;/pre&gt; &lt;p&gt;This will create a new Angular project, and as with the React example, we can run another command to deploy:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --strictSSL=false --dockerImage=bucharestgold/centos7-s2i-web-app --imageTag=10.x --build.env OUTPUT_DIR=dist/angular-web-app --expose &lt;/pre&gt; &lt;p&gt;Again, similar to the React application, your OpenShift web console will look something like this:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick.png"&gt;&lt;img class=" aligncenter wp-image-521767 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick-1024x520.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick-1024x520.png" alt="Screenshot of the OpenShift web console after deploying an Angular app" width="640" height="325" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick-1024x520.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick-300x152.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-quick-768x390.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;And here&amp;#8217;s what the web console looks like when you run the application:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift.png"&gt;&lt;img class=" aligncenter wp-image-521777 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift-1024x561.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift-1024x561.png" alt="Screenshot of what the web console looks like when you run the Angular app" width="640" height="351" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift-1024x561.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift-768x421.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/angular-on-openshift.png 1539w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s take a look at that command again. Even though it looks very similar to the command we used for the React app, there is are some very important differences.&lt;/p&gt; &lt;p&gt;The differences are with the &lt;code&gt;build.env&lt;/code&gt; flag: &lt;code&gt;--build.env OUTPUT_DIR=dist/angular-web-app&lt;/code&gt;. There are two things different here.&lt;/p&gt; &lt;p&gt;First, we removed the &lt;code&gt;YARN_ENABLED&lt;/code&gt; variable, since we aren&amp;#8217;t using yarn for the Angular project.&lt;/p&gt; &lt;p&gt;The second is the addition of the &lt;code&gt;OUTPUT_DIR=dist/angular-web-app&lt;/code&gt; variable. So, by default, the S2I image will look for your compiled code in the &lt;code&gt;build&lt;/code&gt; directory. React uses &lt;code&gt;build&lt;/code&gt; by default; that is why we didn&amp;#8217;t set it for that example. However, Angular uses something different for its compiled output. It uses &lt;code&gt;dist/&amp;#60;PROJECT_NAME&amp;#62;&lt;/code&gt;, which in our case is &lt;code&gt;dist/angular-web-app&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;For those who skipped to this section to see the two commands to run, here they are:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;React:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;$ npx create-react-app react-web-app $ npx nodeshift --strictSSL=false --dockerImage=bucharestgold/centos7-s2i-web-app --imageTag=10.x --build.env YARN_ENABLED=true --expose &lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Angular:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;$ npx @angular/cli new angular-web-app $ npx nodeshift --strictSSL=false --dockerImage=bucharestgold/centos7-s2i-web-app --imageTag=10.x --build.env OUTPUT_DIR=dist/angular-web-app --expose &lt;/pre&gt; &lt;p&gt;In this post, we saw how quickly and easily we can deploy a modern web app to OpenShift using the new S2I Web App Builder image. The examples use the community version of the image, but very soon there will be an official &lt;a href="https://developers.redhat.com/products/rhoar/overview/"&gt;Red Hat Openshift Application Runtime (RHOAR)&lt;/a&gt; tech preview release. So watch out for that.&lt;/p&gt; &lt;p&gt;In the coming posts, we will take a deeper look at what the image is actually doing and how we can use more of its advanced features, as well as some advanced features of OpenShift, to deploy a more production-worthy application.&lt;/p&gt; &lt;p&gt;Stay tuned.&lt;/p&gt; &lt;hr /&gt; &lt;p&gt;&lt;strong&gt;For more information download the free ebook &lt;em&gt;&lt;a href="https://developers.redhat.com/books/deploying-openshift/"&gt;Deploying to OpenShift&lt;/a&gt;&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;linkname=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F04%2Fmodern-web-apps-openshift-part-1%2F&amp;#38;title=Modern%20Web%20Applications%20on%20OpenShift%3A%20Part%201%20%E2%80%93%20Web%20apps%20in%20two%20commands" data-a2a-url="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/" data-a2a-title="Modern Web Applications on OpenShift: Part 1 – Web apps in two commands"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/"&gt;Modern Web Applications on OpenShift: Part 1 &amp;#8211; Web apps in two commands&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/klACS25fJiI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this multi-part series, we will take a look at how to deploy modern web applications, like React and Angular apps, to Red Hat OpenShift using a new source-to-image (S2I) builder image. This first post will cover how to deploy modern web apps using the fewest steps. The next post will show how to combine [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/"&gt;Modern Web Applications on OpenShift: Part 1 &amp;#8211; Web apps in two commands&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">516177</post-id><dc:creator>Lucas Holmquist</dc:creator><dc:date>2018-10-04T17:00:23Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 19/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/8TygzaDi13I/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_19_2018</id><updated>2018-10-04T05:55:27Z</updated><published>2018-10-04T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Arnold Gálovics continues his concurrency control series with &lt;a href="https://blog.arnoldgalovics.com/pessimistic-locking-in-jpa-hibernate/"&gt;this article about pessimistic locking in JPA and Hibernate&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Debezium allows you to parse the database transaction log and extract changes. You can use the change events to maintain a materialized view or update an application-level cache. In &lt;a href="https://debezium.io/blog/2018/09/20/materializing-aggregate-views-with-hibernate-and-debezium/"&gt;this article&lt;/a&gt;, you are going to find how to materialize aggregate views with Hibernate and Debezium.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Spring framework 5.1 has been released with a Hibernate optimization for read-only transactions. Check out &lt;a href="https://vladmihalcea.com/spring-read-only-transaction-hibernate-optimization/"&gt;this article&lt;/a&gt; for more details.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Eugen Paraschiv published two articles on his website:&lt;/p&gt; &lt;/div&gt; &lt;div class="olist arabic"&gt; &lt;ol class="arabic"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.baeldung.com/hibernate-save-persist-update-merge-saveorupdate"&gt;The first article&lt;/a&gt;, explains the difference between the JPA &lt;code&gt;EntityManager&lt;/code&gt; &lt;code&gt;persist&lt;/code&gt;, &lt;code&gt;merge&lt;/code&gt; methods and the Hibernate-specific &lt;code&gt;Session&lt;/code&gt; &lt;code&gt;save&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt; and &lt;code&gt;saveOrUpdate&lt;/code&gt; methods.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.baeldung.com/hibernate-date-time"&gt;The second article&lt;/a&gt; explains how to persist Date and Time objects with JPA and Hibernate.&lt;/p&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you are using SAP HANA, &lt;a href="https://developers.sap.com/romania/tutorials/hana-hibernate-setup.html"&gt;this article&lt;/a&gt; explains how to setup Hibernate for SAP HANA in your Eclipse project.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="time-to-upgrade"&gt;&lt;a class="anchor" href="#time-to-upgrade"&gt;&lt;/a&gt;Time to upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="http://in.relation.to/2018/10/01/hibernate-ogm-5-4-CR1-released/"&gt;Hibernate OGM 5.4 CR1&lt;/a&gt; has been released bringing the following features:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;support Infinispan remote transactions over HotRod client,&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Java types &lt;code&gt;java.time.LocalDate&lt;/code&gt;, &lt;code&gt;java.time.LocalDateTime&lt;/code&gt; and &lt;code&gt;java.time.LocalTime&lt;/code&gt; are natively supported as field types,&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;configure the MongoDB ReadConcern strategy.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/org-hibernate-mappingexception-no-dialect-mapping-for-jdbc-type-9/1412/2"&gt;Hibernate throws org.hibernate.MappingException: No Dialect mapping for JDBC type: -9 with Oracle dialect&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-can-add-costomflushingeventlistener-jpa-in-spring-boot/1414"&gt;How to add a custom Hibernate FlushingEventListener with Spring Boot&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/5155718/hibernate-performance"&gt;Hibernate Performance Tips&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/a/41507047/1025118"&gt;How can we call a stored procedure with Hibernate and JPA?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-log-the-class-and-method-that-generated-a-given-sql-query-with-jpa-and-hibernate/1421"&gt;How to log the class and method that generated a given SQL query with JPA and Hibernate &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.quora.com/What-are-some-differences-between-Spring-caching-and-Hibernate-caching/answer/Vlad-Mihalcea-1"&gt;What are some differences between Spring caching and Hibernate caching?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.quora.com/What-is-hibernate-cache-mechanism/answer/Vlad-Mihalcea-1"&gt;What is the Hibernate cache mechanism?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.quora.com/Is-stored-procedure-better-than-any-ORM-frameworks-like-hibernate-or-is-it-the-other-way"&gt;Is using stored procedures better than any ORM frameworks like Hibernate or is it the other way around?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-throws-caused-by-org-hibernate-hql-internal-ast-querysyntaxexception-memoryspace-is-not-mapped/1317"&gt;Hibernate throws “Caused by: org.hibernate.hql.internal.ast.QuerySyntaxException: MemorySpace is not mapped”&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.quora.com/How-do-I-use-where-clause-in-hibernate-mapping-file"&gt;How do I use the @Where clause in Hibernate HBM XML mapping file?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52519013/hibernate-6-what-is-sqm/52584844#52584844"&gt;Hibernate 6: What is SQM?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/23825060/embeddeble-pk-nullable-field-no-returns/23888014#23888014"&gt;JPA Embeddeble PK and nullable field&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/28495817/how-to-load-the-actual-hibernate-entity-association-and-not-the-lazy-proxy/28538427#28538427"&gt;How to load the actual Hibernate entity association and not the LAZY proxy&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-l2-cache-for-many-many-relationship-in-a-joining-table/1480"&gt;Hibernate second-level cache for many-many relationship in a joining table&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/resultset-holdability-not-working-with-hibernate/1445/10"&gt;ResultSet Holdability not working with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/8TygzaDi13I" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Articles Arnold Gálovics continues his concurrency control series with this article about pessimistic locking in JPA and Hibernate. Debezium allows you to parse the database transaction log and extract changes. You can use the change events to ma...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-10-04T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/04/hibernate-community-newsletter-2018-19/</feedburner:origLink></entry><entry><title>Cloud Native Container Design Principles</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rIk4rvNXKYI/cloud-native-container-design-principles.html" /><category term="Cloud Native" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="design" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_ofbizian" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-cloud_native_container_design_principles</id><updated>2018-10-04T09:23:50Z</updated><published>2018-10-03T05:48:00Z</published><content type="html">&lt;h3&gt;&lt;span style="font-weight: normal;"&gt;&lt;span class="markup--strong markup--h4-strong"&gt;Creating a containerized application that behave like a good cloud native citizen and can be automated effectively by a cloud native platform such as Kubernetes requires some discipline. See below what it&amp;nbsp;is. &lt;/span&gt;&lt;i&gt;(Alternatively, read the same post on &lt;a href="https://medium.com/p/144ceaa98dba/edit" target="_blank"&gt;Medium&lt;/a&gt;)&lt;/i&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h2&gt;Software design principles&lt;/h2&gt;Principles exist in many areas of life, and they generally represent a fundamental truth or belief from which others are derived. In software, principles are rather abstract guidelines, which are supposed to be followed while designing software. There are fundamental principles for writing quality software such as KISS (Keep it simple, stupid), DRY (Don’t repeat yourself), YAGNI (You aren’t gonna need it), SoC (Separation of concerns), etc. Even if these principles do not specify concrete rules, they represent a language and common wisdom that many developers understand and refer to regularly.&lt;br /&gt;&lt;br /&gt;There are also SOLID principles that were introduced by &lt;a href="https://twitter.com/unclebobmartin" target="_blank"&gt;Robert C. Martin&lt;/a&gt;, which represent guidelines for writing better object-oriented software. It is a framework consisting of complementary principles that are generic and open for interpretation but still give enough direction for creating better object-oriented designs. The SOLID principles use object-oriented primitives and concepts such as classes, interfaces, and inheritance for reasoning about object-oriented designs. In a similar way, there also principles for designing cloud native applications in which the main primitive is the container image rather than a class. Following these principles will ensure that the resulting containers behave like a good cloud native citizen, allowing them to be scheduled, scaled, and monitored in an automated fashion.&lt;br /&gt;&lt;h2&gt;SOLID principles for cloud native applications&lt;/h2&gt;Cloud native applications anticipate failure; they run and scale reliably even when their infrastructure experiences outages. To offer such capabilities, cloud native platforms like Kubernetes impose a set of contracts on applications. These contracts ensure that applications they run conform to certain constraints and allow the platform to automate application management. Nowadays, it is possible to put almost any application in a container and run it. But to create a containerized application that can be automated and orchestrated effectively by a cloud native platform such as Kubernetes requires additional efforts. The principles for creating containerized applications listed here use the container as the basic primitive and the container orchestration platforms as the target container runtime environment.&lt;br /&gt;&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-B0bJ_kaJpac/W7IdwIAZiyI/AAAAAAAALcs/ZSGXXv737j0rJZyqJhDraWp_8HxTK50kwCLcBGAs/s1600/cloud_native_design_principles.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="789" data-original-width="1600" height="195" src="https://4.bp.blogspot.com/-B0bJ_kaJpac/W7IdwIAZiyI/AAAAAAAALcs/ZSGXXv737j0rJZyqJhDraWp_8HxTK50kwCLcBGAs/s400/cloud_native_design_principles.png" width="400" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;div class="heading2"&gt;&lt;i&gt;Principles of container-based application design&lt;/i&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Below is a short summary of what each principle dictates. To read in more details, download the freely available white paper from &lt;a href="https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper" target="_blank"&gt;here&lt;/a&gt; (no signup required).&lt;br /&gt;&lt;h3&gt;&lt;b&gt;Build time&lt;/b&gt;:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Single Concern&lt;/b&gt;: Each container addresses a single concern and does it well.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Self-Containment&lt;/b&gt;: A container relies only on the presence of the Linux kernel. Additional libraries are added when the container is built.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Image Immutability&lt;/b&gt;: Containerized applications are meant to be immutable, and once built are not expected to change between different environments.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Runtime&lt;/b&gt;:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;High Observability&lt;/b&gt;: Every container must implement all necessary APIs to help the platform observe and manage the application in the best way possible.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Lifecycle Conformance&lt;/b&gt;: A container must have a way to read events coming from the platform and conform by reacting to those events.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Process Disposability&lt;/b&gt;: Containerized applications must be as ephemeral as possible and ready to be replaced by another container instance at any point in time.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Runtime Confinement&lt;/b&gt;: Every container must declare its resource requirements and restrict resource use to the requirements indicated.&lt;/li&gt;&lt;/ul&gt;The build time principles ensure that containers have the right granularity, consistency, and structure in place. The runtime principles dictate what functionalities must be implemented in order for containerized applications to possess cloud native function. Adhering these principles, we are more likely to create containerized applications that are better suited for automation in cloud native platforms such as Kubernetes. Check out the &lt;a href="https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper" target="_blank"&gt;white paper&lt;/a&gt; for more details.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rIk4rvNXKYI" height="1" width="1" alt=""/&gt;</content><summary>Creating a containerized application that behave like a good cloud native citizen and can be automated effectively by a cloud native platform such as Kubernetes requires some discipline. See below what it is. (Alternatively, read the same post on Medium) Software design principlesPrinciples exist in many areas of life, and they generally represent a fundamental truth or belief from which others ar...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2018-10-03T05:48:00Z</dc:date><feedburner:origLink>http://www.ofbizian.com/2018/10/cloud-native-container-design-principles.html</feedburner:origLink></entry><entry><title>Are App Servers Dead in the Age of Kubernetes? (Part 2)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/HrNb7Yk6WRg/" /><category term="Containers" /><category term="Java" /><category term="Microservices" /><category term="Modern App Dev" /><category term="Red Hat OpenShift Container Platform" /><category term="ci/cd" /><category term="containers" /><category term="kubernetes" /><category term="MicroProfile" /><category term="microservices" /><category term="Red Hat JBoss EAP" /><category term="Red Hat OpenShift" /><author><name>Ken Finnigan</name></author><id>https://developers.redhat.com/blog/?p=519087</id><updated>2018-10-03T01:42:16Z</updated><published>2018-10-03T01:42:16Z</published><content type="html">&lt;p&gt;Welcome to the second in a series of posts on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;, application servers, and the future. Part 1, &lt;a href="https://developers.redhat.com/blog/2018/09/05/kubernetes-new-operating-environment"&gt;Kubernetes is the new application operating environment&lt;/a&gt;, discussed Kubernetes and its place in application development. In this part, we explore application servers and their role in relation to Kubernetes.&lt;/p&gt; &lt;p&gt;You may recall from &lt;a href="https://developers.redhat.com/blog/2018/09/05/kubernetes-new-operating-environment" rel="prev"&gt;Part 1&lt;/a&gt; that we were exploring the views put forth in &lt;a href="https://developers.redhat.com/blog/2018/06/28/why-kubernetes-is-the-new-application-server/"&gt;Why Kubernetes is The New Application Server&lt;/a&gt; and thinking about what those views mean for Java EE, &lt;a href="https://developers.redhat.com/blog/2018/04/24/jakarta-ee-is-officially-out/"&gt;Jakarta EE&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/tag/microprofile/"&gt;Eclipse MicroProfile&lt;/a&gt;, and application servers. Is it a curtain call for application servers? Are we seeing the start of an imminent decline in their favor and usage?&lt;/p&gt; &lt;p&gt;Before answering that, we need to discuss the use case for application servers. Then can we decide whether it’s still a valid use case.&lt;/p&gt; &lt;p&gt;&lt;span id="more-519087"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;What is an application server good for?&lt;/h2&gt; &lt;p&gt;Why do we have application servers? What’s their purpose? These are some of the questions we could ask when thinking about their problem space.&lt;/p&gt; &lt;p&gt;Application servers didn’t spring up out of nowhere for no reason. They were an evolution of the CORBA and DCOM models offering separate services for security, transactions, messaging, etc. All these services being separated required lots of communication between them.&lt;/p&gt; &lt;p&gt;Application servers were born out of the need to bring all these services under a single process. In addition to co-locating the services, they provided a framework on top making it easier to combine the capabilities of the services.&lt;/p&gt; &lt;p&gt;Sound familiar? Indeed it does. CORBA and DCOM are architecturally similar to what we call &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; today.&lt;/p&gt; &lt;h2&gt;Is now the death of application servers?&lt;/h2&gt; &lt;p&gt;Kubernetes is not the death knell for application servers as we know them today. Application servers have always evolved—and will continue to evolve—as hardware and software improve. Continual improvements are being made in developer productivity. Kubernetes, Docker and, now, &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;service mesh&lt;/a&gt; are another step in the evolution that necessitates a shift in application servers. It doesn’t make them irrelevant.&lt;/p&gt; &lt;h2&gt;Application servers reborn&lt;/h2&gt; &lt;p&gt;If anything, the advent of Kubernetes as an operating environment will lead to another transformation of application servers. Like a Phoenix from the ashes, application servers will transform themselves, as happened in the past many times.&lt;/p&gt; &lt;p&gt;The first post talked about taking into account both what Kubernetes provides and what our application or microservice needs. It noted that Kubernetes is a fine application server for deployments that don’t interact with lots of other services. Conversely, most Java EE and MicroProfile applications are not so isolated that they can be treated in such a manner.&lt;/p&gt; &lt;p&gt;Let’s take a look at why Java EE and MicroProfile applications are usually less isolated. Whether applications are in a single process or they are distributed across a network, they consist of many services working together towards a business objective—though they likely didn’t start that way.&lt;/p&gt; &lt;p&gt;Applications created with a single business objective quickly grow as business needs change over time. Or an application developed by one person needs to be altered for wider usage. There are many reasons that applications need to grow and adjust. Complicating it is that in the beginning, we usually don’t know an application will grow.&lt;/p&gt; &lt;h2&gt;Kubernetes as an application server&lt;/h2&gt; &lt;p&gt;Planning for a simple application using Kubernetes as the application server quickly leads to problems as the application expands beyond the initial goals, requiring frameworks to integrate and provide functionality above that offered by Kubernetes itself.&lt;/p&gt; &lt;p&gt;Applications usually interact with other applications, services, and systems or with pretty much anything outside themselves. Doing so guarantees an application will need things such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Integration with messaging systems for asynchronous or offline processing&lt;/li&gt; &lt;li&gt;Transactions within itself and across other invocations&lt;/li&gt; &lt;li&gt;Fine-grained security controls, as opposed to coarse-grained security controls&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These are all crucial things provided by application servers and fat JARs for applications and microservices today, whether you’re using WildFly or &lt;a href="https://developers.redhat.com/blog/2018/08/23/eclipse-microprofile-and-red-hat-update-thorntail-and-smallrye/"&gt;Thorntail&lt;/a&gt; to deploy into. These concerns aren’t going away, and they’re not offered by Kubernetes or other projects that build on top of it, such as &lt;a href="http://openshift.com/"&gt;Red Hat OpenShift&lt;/a&gt; and &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Istio&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Coming in Part 3&lt;/h2&gt; &lt;p&gt;The final part of this series will bring to a close our analysis. It will answer the following question for Kubernetes and application servers: Can they co-exist?&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;linkname=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F02%2Fare-app-servers-dead-in-the-age-of-kubernetes-part-2%2F&amp;#38;title=Are%20App%20Servers%20Dead%20in%20the%20Age%20of%20Kubernetes%3F%20%28Part%202%29" data-a2a-url="https://developers.redhat.com/blog/2018/10/02/are-app-servers-dead-in-the-age-of-kubernetes-part-2/" data-a2a-title="Are App Servers Dead in the Age of Kubernetes? (Part 2)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/02/are-app-servers-dead-in-the-age-of-kubernetes-part-2/"&gt;Are App Servers Dead in the Age of Kubernetes? (Part 2)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/HrNb7Yk6WRg" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Welcome to the second in a series of posts on Kubernetes, application servers, and the future. Part 1, Kubernetes is the new application operating environment, discussed Kubernetes and its place in application development. In this part, we explore application servers and their role in relation to Kubernetes. You may recall from Part 1 that we were [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/02/are-app-servers-dead-in-the-age-of-kubernetes-part-2/"&gt;Are App Servers Dead in the Age of Kubernetes? (Part 2)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/02/are-app-servers-dead-in-the-age-of-kubernetes-part-2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">519087</post-id><dc:creator>Ken Finnigan</dc:creator><dc:date>2018-10-03T01:42:16Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/02/are-app-servers-dead-in-the-age-of-kubernetes-part-2/</feedburner:origLink></entry><entry><title>Segmented Data Containers: Distributed Stream Performance Boost</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/hceYdRWp58Q/segmented-data-containers-distributed.html" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><author><name>William Burns</name></author><id>searchisko:content:id:jbossorg_blog-segmented_data_containers_distributed_stream_performance_boost</id><updated>2018-10-03T12:11:59Z</updated><published>2018-10-02T18:11:00Z</published><content type="html">Welcome to the first of several blog posts that describe the segmentation of containers that Infinispan uses to store data. Some of you may have noticed in the previous &lt;a href="https://blog.infinispan.org/2018/06/infinispan-930final-is-out.html"&gt;9.3.0.Final notes&lt;/a&gt; that we announced a new feature named “Segmented On-Heap Data Container”. We also mentioned that “It improves performance of stream operations”, but what does that really mean?&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;What is a segmented data container and why does it matter?&amp;nbsp;&lt;/h3&gt;&lt;br /&gt;Imagine a cluster of 4 nodes in distributed mode (&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;numOwners = 2&lt;/span&gt;) with entries for &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;k0 - k13&lt;/span&gt;. It might look like this:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-5FopP39_Z6k/W7O94C_HrAI/AAAAAAAAeDM/xWnwzer_RP8gQBlZvDI5MOY-Qroof7S_gCLcBGAs/s1600/NonSegmentedData.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="571" data-original-width="642" height="568" src="https://2.bp.blogspot.com/-5FopP39_Z6k/W7O94C_HrAI/AAAAAAAAeDM/xWnwzer_RP8gQBlZvDI5MOY-Qroof7S_gCLcBGAs/s640/NonSegmentedData.jpg" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;The data is distributed between the nodes with only two copies of each entry available. However, the data itself is stored internally in the same Map instance. As a result, when performing operations on all entries in the cache, Infinispan must iterate over the same data multiple times. This degrades performance. &lt;br /&gt;&lt;br /&gt;As of Infinispan 9.3, a segmented data container is available to separate data by segments. Although only on-heap bounded and unbounded implementations are currently available. &lt;br /&gt;&lt;br /&gt;With a segmented data container, that same data set might look like this:&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-7S1k7hNmrHI/W7O99geUbkI/AAAAAAAAeDQ/k5tbJq0w22ovQxpNG2uXcMIV63HIvz4MQCLcBGAs/s1600/SegmentedData.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="570" data-original-width="647" height="562" src="https://2.bp.blogspot.com/-7S1k7hNmrHI/W7O99geUbkI/AAAAAAAAeDQ/k5tbJq0w22ovQxpNG2uXcMIV63HIvz4MQCLcBGAs/s640/SegmentedData.jpg" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Because Infinispan internally reasons on data in terms of segments, a segmented data container lets Infinispan process data only in specific segments. This allows for operations performed upon all entries to require iteration over the data only once.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;Actual Performance Difference&lt;/h3&gt;&lt;br /&gt;So with the above example you might be thinking that the performance increase maximum is two times throughput, since &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;numOwners&lt;/span&gt; is two. This is close, but not quite correct. While iterating on the data we also have to determine what segment an entry belongs to. With a segmented container we know this already, so there is no need to calculate that. This provides additional performance, as you will see.&lt;br /&gt;&lt;br /&gt;The following graphs were generated using the benchmark at &lt;a href="https://github.com/infinispan/infinispan-benchmarks/tree/master/iteration"&gt;https://github.com/infinispan/infinispan-benchmarks/tree/master/iteration&lt;/a&gt;. The following command was run: &lt;b&gt;java -jar target/benchmarks.jar -pvalueObjectSize=1000 -pentryAmount=50000 -pbatchSize=4096&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;&lt;span id="docs-internal-guid-9b20945e-7fff-7241-2261-95b975ba8902" style="background-color: transparent; color: black; font-family: &amp;quot;arial&amp;quot;; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre;"&gt;&lt;img height="385" src="https://lh6.googleusercontent.com/XMXQWsWISdPTt-93vLV5RgnJld-ASxkiWaXDZ-O1guXkoe87fYj1Ra2mlQHfcnTmVlXKNTZhk5T095pL99PjqlHgCbqlpFLyvQoTSBarR65wO275T7syowLSBxZl8syWKSYF9H43" style="-webkit-transform: rotate(0.00rad); border: none; transform: rotate(0.00rad);" title="Chart" width="624" /&gt;&lt;/span&gt; &lt;/b&gt;&lt;br /&gt;&lt;br /&gt;The preceding graph is the result of the iteration methods. As you can notice the performance increase isn’t that much… why not?!?&lt;br /&gt;&lt;br /&gt;Unfortunately, remote iteration requires a lot of network overhead, so we don’t get to see the full benefits of segmentation. But at least it is about 5-12% faster, not too shabby.&lt;br /&gt;&lt;br /&gt;Now to show the real improvement, here is the chart showing the performance increase for the &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Cache#size&lt;/span&gt; operation:&lt;br /&gt;&lt;br /&gt;&lt;span id="docs-internal-guid-413b551a-7fff-9931-559d-9fda906ad6b1" style="background-color: transparent; color: black; font-family: &amp;quot;arial&amp;quot;; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;"&gt;&lt;img height="385" src="https://lh6.googleusercontent.com/HHbRs5_4t4jE_7j8l3ArlsuPCgFXjh7zZXLGJXo3e9LLOP-matr7qTGzLiH8RpW9at1IimMrtC-LNKSsQmAujhMjVXxj31ruTGfEHeP9J-rTpUIFo0WjoyY_NCezBD6WtUj2NVgy" style="-webkit-transform: rotate(0.00rad); border: none; transform: rotate(0.00rad);" title="Chart" width="624" /&gt;&lt;/span&gt; &lt;br /&gt;&lt;br /&gt;If you notice there is &lt;b&gt;huge&lt;/b&gt; increase in performance: almost a three fold increase over the non-segmented container, even though &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;numOwners&lt;/span&gt; is only two. The old segment calculation adds a bit of overhead compared to just incrementing a number.&lt;br /&gt;&lt;br /&gt;So keep in mind this change will show a larger gain in performance if the result returned is smaller, especially if it is a fixed size, such as a single &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;int&lt;/span&gt; for &lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;Cache#size&lt;/span&gt;.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;What about gets and puts?&lt;/h3&gt;&lt;br /&gt;Having the container segmented should also affect get and put performance as well, right? In testing the difference for get and puts are less than one percent, in favor of segmentation due to some optimizations we were able to add.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;How do I enable this?&lt;/h3&gt;&lt;br /&gt;So the performance gains are noticeable, especially when the remote operation returns a small data set. But how can a user configure this? This is the nice part, due to no performance loss with other operations the container will always be segmented as long as the cache mode supports segmentation. That is if it is a Distributed, Replicated or Scattered cache.&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;A real-life example and closing&lt;/h3&gt;&lt;br /&gt;Since this feature has been around a while already, we actually have users gaining benefits from this feature. An example can be found at &lt;a href="https://developer.jboss.org/message/983837#983837"&gt;https://developer.jboss.org/message/983837#983837&lt;/a&gt;. In this case the user only upgraded to Infinispan 9.3 and received over a three-fold increase in performance when using distributed streams. It actually starts to bring distributed streams performance within range of indexed query for some use cases.&lt;br /&gt;&lt;br /&gt;So, by upgrading your application to Infinispan 9.3 or newer, you will benefit from these improvements. There will be future posts regarding segmentation, including support for stores. Either way please feel free to &lt;a href="http://infinispan.org/download/"&gt;download Infinispan&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on the &lt;a href="https://developer.jboss.org/en/infinispan/content"&gt;forum&lt;/a&gt; or on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;img src="http://feeds.feedburner.com/~r/Infinispan/~4/Wnt_SoEKS1Y" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/hceYdRWp58Q" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the first of several blog posts that describe the segmentation of containers that Infinispan uses to store data. Some of you may have noticed in the previous 9.3.0.Final notes that we announced a new feature named “Segmented On-Heap Data Container”. We also mentioned that “It improves performance of stream operations”, but what does that really mean? What is a segmented data container a...</summary><dc:creator>William Burns</dc:creator><dc:date>2018-10-02T18:11:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/Infinispan/~3/Wnt_SoEKS1Y/segmented-data-containers-distributed.html</feedburner:origLink></entry><entry><title>DMN webinar on October 18, 2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DR9wucz5U34/dmn-webinar-on-october-18-2018-rule.html" /><category term="feed_group_name_drools" scheme="searchisko:content:tags" /><category term="feed_name_drools" scheme="searchisko:content:tags" /><author><name>Mario Fusco</name></author><id>searchisko:content:id:jbossorg_blog-dmn_webinar_on_october_18_2018</id><updated>2018-10-02T15:29:58Z</updated><published>2018-10-02T15:27:00Z</published><content type="html">&lt;br /&gt;Rule engines are a powerful yet flexible tool to define and implement huge sets of business requirements and constraints. While Drools Rule Language (DRL) may be appealing to define business rules for technically savvy domain experts, a new visual based standard has emerged in the Decision Management space to bridge the gap between technical and business analyst: the Object Management Group published in 2015 the Decision Model &amp;amp; Notation, a specification for a graphical decision language, expressly designed for business users.&lt;br /&gt;&lt;br /&gt;Drools provides an open source execution engine with full DMN support at conformance level 3. If you're curious to know more about this there's no better way than joining &lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;Phil Simpson and &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;Denis Gagne &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;in his&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;a href="https://middlewareblog.redhat.com/2018/09/27/decision-model-notation-a-new-approach-to-business-rules/" target="_blank"&gt;free webinar&lt;/a&gt; &lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;on October 18 at 1pm ET&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; where he will explore in details the features of this new standard.&lt;br /&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=n6cF7eBugsw:1M5Iap3MRw4:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:dnMXMwOfBR0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=dnMXMwOfBR0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=n6cF7eBugsw:1M5Iap3MRw4:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=n6cF7eBugsw:1M5Iap3MRw4:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=n6cF7eBugsw:1M5Iap3MRw4:jWeZv7XsJd0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=jWeZv7XsJd0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/DroolsAtom/~4/n6cF7eBugsw" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DR9wucz5U34" height="1" width="1" alt=""/&gt;</content><summary>Rule engines are a powerful yet flexible tool to define and implement huge sets of business requirements and constraints. While Drools Rule Language (DRL) may be appealing to define business rules for technically savvy domain experts, a new visual based standard has emerged in the Decision Management space to bridge the gap between technical and business analyst: the Object Management Group publis...</summary><dc:creator>Mario Fusco</dc:creator><dc:date>2018-10-02T15:27:00Z</dc:date><feedburner:origLink>http://feeds.athico.com/~r/DroolsAtom/~3/n6cF7eBugsw/dmn-webinar-on-october-18-2018-rule.html</feedburner:origLink></entry><entry><title>Linux Foundation ONS Europe 2018 session slides</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/HaAOLW3KoZs/linux-foundation-ons-europe-2018-session-slides.html" /><category term="cloud" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="event" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenStack" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-linux_foundation_ons_europe_2018_session_slides</id><updated>2018-10-05T07:35:08Z</updated><published>2018-10-02T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="https://linuxfoundation.smapply.io/prog/open_networking_summit_europe_2018/" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="linux foundation" border="0" data-original-height="84" data-original-width="632" height="42" src="https://1.bp.blogspot.com/-abBRbL6zDSM/WzNC25YazBI/AAAAAAAAsz4/VCF19q1BXssrN1v1X2agl0Q7l2-nGwl-QCLcBGAs/s320/2018_EventBanners_ONS-EU.jpg" title="" width="320" /&gt;&lt;/a&gt;&lt;br /&gt;I &lt;a href="http://www.schabell.org/2018/08/open-networking-summit-europe-2018-3-pitfalls-hybrid-multicloud-accepted.html" target="_blank"&gt;mentioned previously&lt;/a&gt; that our talk was accepted for The Linux Foundation&amp;nbsp;&lt;a href="https://linuxfoundation.smapply.io/prog/open_networking_summit_europe_2018/" target="_blank"&gt;Open Networking Summit Europe (ONS) 2018&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;ONS brings together business and technical leaders across enterprise, cloud and service providers to share learnings, highlight innovation and discuss the future of open networking and orchestration. ONS Europe will feature 3 days of sessions, including project-based technical sessions, tutorials, workshops, keynotes and more.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://4.bp.blogspot.com/-xxhtz39FqFw/W7MxDK9yQLI/AAAAAAAAtIk/IOyBQHisepUIHK3kM909sfOtTUP84KFcgCLcBGAs/s1600/IMG_0160.JPG" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="3 pitfalls" border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://4.bp.blogspot.com/-xxhtz39FqFw/W7MxDK9yQLI/AAAAAAAAtIk/IOyBQHisepUIHK3kM909sfOtTUP84KFcgCLcBGAs/s320/IMG_0160.JPG" title="" width="320" /&gt;&lt;/a&gt;Last week my co-presenter and I hosted a little over 30 attendees for a talk around pitfalls everyone should avoid with hybrid multicloud.&lt;br /&gt;&lt;br /&gt;As part of the session a lively discussion was setup through the attendee participation in live polling, spread throughout the presentation slides.&lt;br /&gt;&lt;br /&gt;To share the results of their polling, we've updated the slides to include a results slide after each poll question, allowing those who missed the session to see how things shake out.&lt;br /&gt;&lt;br /&gt;Check out the slides below:&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;&lt;i&gt;&lt;a href="http://sched.co/Fms2" target="_blank"&gt;3 Pitfalls Everyone Should Avoid with Hybrid Multicloud&lt;/a&gt;&lt;/i&gt;&lt;/h3&gt;&lt;div&gt;&lt;i&gt;The daily hype is all around you. From cloud, hybrid cloud, to hybrid multi-cloud, you’re told this is the way to ensure a digital future for your business. These choices you’ve got to make don’t preclude the daily work of enhancing your customer's experience and agile delivery of those applications. Let us take you on a journey, looking closely at what hybrid multi-cloud means for your business, the decisions being made about delivering applications, and dealing with legacy applications, likely the most important resources to your business. Join us for an hour of power, where real customer experiences are used to highlight the three top lessons learned as they transitioned into hybrid multi-cloud environments.&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt; &lt;i&gt;Co-speaker: &lt;a href="https://twitter.com/roelhodzelmans" target="_blank"&gt;Roel Hodzelmans&lt;/a&gt;&lt;/i&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;iframe allowfullscreen="" frameborder="0" height="420" marginheight="0" marginwidth="0" scrolling="no" src="//www.slideshare.net/slideshow/embed_code/key/CmzoDVpemtUIN4" style="border-width: 1px; border: 1px solid #ccc; margin-bottom: 5px; max-width: 100%;" width="510"&gt; &lt;/iframe&gt;&lt;/div&gt;&lt;br /&gt;Thanks for those that attended and shared their insights into the same problems they've encountered.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=BkVycs6a6p8:kNCSieMSB5o:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=BkVycs6a6p8:kNCSieMSB5o:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=BkVycs6a6p8:kNCSieMSB5o:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=BkVycs6a6p8:kNCSieMSB5o:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=BkVycs6a6p8:kNCSieMSB5o:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/BkVycs6a6p8" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/HaAOLW3KoZs" height="1" width="1" alt=""/&gt;</content><summary>I mentioned previously that our talk was accepted for The Linux Foundation Open Networking Summit Europe (ONS) 2018. ONS brings together business and technical leaders across enterprise, cloud and service providers to share learnings, highlight innovation and discuss the future of open networking and orchestration. ONS Europe will feature 3 days of sessions, including project-based technical sessi...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2018-10-02T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/BkVycs6a6p8/linux-foundation-ons-europe-2018-session-slides.html</feedburner:origLink></entry><entry><title>Microservices Batch Application with Thorntail and OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Fg8Orfw7l9U/microservices-batch-application-with-thorntail-and-openshift" /><category term="feed_group_name_jberet" scheme="searchisko:content:tags" /><category term="feed_name_jberet" scheme="searchisko:content:tags" /><category term="jberet" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="thorntail" scheme="searchisko:content:tags" /><author><name>Cheng Fang</name></author><id>searchisko:content:id:jbossorg_blog-microservices_batch_application_with_thorntail_and_openshift</id><updated>2018-10-02T03:43:55Z</updated><published>2018-10-02T03:43:55Z</published><content type="html">&lt;!-- [DocumentBodyStart:676756fe-8f94-4704-a5e2-552ba939c820] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;h2&gt;Introduction&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;This blog post is the part of the series that showcase some of the work in &lt;a class="jive-link-external-small" href="https://github.com/jberet/" rel="nofollow"&gt;JBeret&lt;/a&gt; family projects for modernizing Java batch processing.&amp;#160; Previously, we've discussed how to move your batch processing workload developed for Java SE standalone environment (&lt;a class="jive-link-blog-small" data-containerId="5311" data-containerType="37" data-objectId="6228" data-objectType="38" href="https://developer.jboss.org/community/jberet/blog/2018/09/17/build-and-deploy-containerized-java-batch-applications-on-openshift"&gt;see this post&lt;/a&gt;) and Java EE platform (&lt;a class="jive-link-blog-small" data-containerId="5311" data-containerType="37" data-objectId="6207" data-objectType="38" href="https://developer.jboss.org/community/jberet/blog/2018/07/02/explore-batch-in-wildfly-13-admin-console"&gt;see this post&lt;/a&gt;) to PaaS such as OpenShift.&amp;#160; They serve as good proof that &lt;a class="jive-link-external-small" href="https://www.jcp.org/en/jsr/detail?id=352" rel="nofollow"&gt;standard-based batch&lt;/a&gt; applications can run with Java SE and Java EE (now &lt;a class="jive-link-external-small" href="https://jakarta.ee/" rel="nofollow"&gt;Jakarta EE&lt;/a&gt;) both locally on bare meta and on cloud platform.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;While it is great to be able to choose from either Java SE or Java EE environment for batch application, you may be wondering if it is possible to take advantage of both: leverage the lightweightness and flexibility of Java SE, and also the wide range of platform service in Java EE.&amp;#160; The answer is yes.&amp;#160; With the advent of &lt;a class="jive-link-external-small" href="https://microprofile.io/" rel="nofollow"&gt;Eclipse MicroProfile&lt;/a&gt;, the new opensource enterprise Java standard for microservices architecture, this type of usecase is well supported.&amp;#160; In this post, we will explore how to build and run microservices batch application with &lt;a class="jive-link-external-small" href="http://wildfly-swarm.io/" rel="nofollow"&gt;Thorntail&lt;/a&gt; (an implementation of Eclipse MicroProfile) both locally and on OpenShift.&amp;#160; We will be using &lt;a class="jive-link-external-small" href="https://github.com/jberet/numbers-chunk-thorntail.git" rel="nofollow"&gt;numbers-chunk-thorntail&lt;/a&gt;, a fully functional sample batch application with Thorntail, to illustrate the steps.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Build and Run Thorntail-based Batch Application Locally&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;First, let's see how to build and run the sample application the traditionaly way locally, and familiarize ourselves with the application structure and batch job.&amp;#160; numbers-chunk-thorntail is a Java EE batch processing application and contains a single batch job as defined in numbers.xml.&amp;#160; Additionally, the project &lt;a class="jive-link-external-small" href="https://github.com/jberet/numbers-chunk-thorntail/blob/master/pom.xml" rel="nofollow"&gt;pom.xml&lt;/a&gt; declares Thorntail-related dependencies and plugins that enhance the regular WAR file into executable Thorntail-style uber jar (fat jar).&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The numbers.xml batch job contains a single chunk-type step that reads a list of numbers by chunks and prints them to the console. The 2 batch artifacts used in this application are:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support/blob/master/src/main/java/org/jberet/support/io/ArrayItemReader.java" rel="nofollow"&gt;arrayItemReader&lt;/a&gt;: implemented in &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support" rel="nofollow"&gt;jberet-support&lt;/a&gt;, reads a list of objects configured in job xml&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support/blob/master/src/main/java/org/jberet/support/io/MockItemWriter.java" rel="nofollow"&gt;mockItemWriter&lt;/a&gt;: implemented in &lt;a class="jive-link-external-small" href="https://github.com/jberet/jberet-support" rel="nofollow"&gt;jberet-support&lt;/a&gt;, writes the output to the console or other destinations&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;This application also contains a singleton EJB, &lt;a class="jive-link-external-small" href="https://github.com/jberet/numbers-chunk-thorntail/blob/master/src/main/java/org/jberet/samples/thorntail/StartUpBean.java" rel="nofollow"&gt;StartUpBean&lt;/a&gt;, which starts execution of batch job numbers.xml upon application deployment and Thorntail server start.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;For complete batch job definition, see the JSL file &lt;a class="jive-link-external-small" href="https://github.com/jberet/numbers-chunk-thorntail/blob/master/src/main/resources/META-INF/batch-jobs/numbers.xml" rel="nofollow"&gt;numbers.xml&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To git-clone the sample application from github:&lt;span class="dp-highlighter"&gt;&lt;/span&gt;&lt;/p&gt;&lt;!--[CodeBlockStart:05104315-afa9-41db-a83c-46ca9fbbf644][excluded]--&gt;&lt;pre class="plain" name="code"&gt;git clone https://github.com/jberet/numbers-chunk-thorntail.git &lt;/pre&gt;&lt;!--[CodeBlockEnd:05104315-afa9-41db-a83c-46ca9fbbf644]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;span class="dp-highlighter"&gt;&lt;/span&gt;To build the sample application with Maven:&lt;/p&gt;&lt;!--[CodeBlockStart:6ecac5ab-aa42-4ce8-b4ac-593d72be3629][excluded]--&gt;&lt;pre class="plain" name="code"&gt;mvn clean install&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:6ecac5ab-aa42-4ce8-b4ac-593d72be3629]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The above step produces both a regular webapp WAR file, and an executable uber jar (fat jar) containing Thorntail runtime and all dependencies:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The above step produces both a regular webapp WAR file, and an executable uber jar (fat jar) containing&lt;/p&gt;&lt;p&gt;Thorntail runtime and all dependencies:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:4817134d-ca34-47fb-a58f-34fefdc13953][excluded]--&gt;&lt;pre class="plain" name="code"&gt;ls -l target/ -rw-r--r--&amp;#160; 1 staff&amp;#160;&amp;#160;&amp;#160;&amp;#160; 258412 Sep 29 14:46 numbers-chunk-thorntail.war -rw-r--r--&amp;#160; 1 staff&amp;#160; 112089497 Sep 29 14:46 numbers-chunk-thorntail-thorntail.jar&lt;/pre&gt;&lt;!--[CodeBlockEnd:4817134d-ca34-47fb-a58f-34fefdc13953]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To run the Thorntail-based application locallym, you can either directly run it with the familiar java -jar command, or with mvn:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:7cf0e1d7-0887-4a72-bada-c3be229550b0][excluded]--&gt;&lt;pre class="plain" name="code"&gt;# Run with java -jar java -jar target/numbers-chunk-thorntail-thorntail.jar # Or run with mvn mvn thorntail:run&lt;/pre&gt;&lt;!--[CodeBlockEnd:7cf0e1d7-0887-4a72-bada-c3be229550b0]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The output should show that Thorntail is bootstrapped, batch application deployed, batch job started and completed, and Thorntail server keeps running.&lt;/p&gt;&lt;p&gt;Apart from this automatically started initial batch job execution, you can perform various batch processing operations with RESTful API calls, thanks to jberet-rest included in this application.&amp;#160; For instance, try the following commands in a separate terminal window:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:baf5b618-0945-47e4-bb3b-152e02323365][excluded]--&gt;&lt;pre class="plain" name="code"&gt;# to start the job named `numbers` curl -s -X POST -H 'Content-Type:application/json' "http://localhost:8080/api/jobs/numbers/start" | jq # to get the details and status of the newly started job execution curl -s "http://localhost:8080/api/jobexecutions/1" | jq # to get all step executions belonging to this job execution curl -s "http://localhost:8080/api/jobexecutions/1/stepexecutions" | jq # to abandon the above job execution curl -X POST -H 'Content-Type:application/json' "http://localhost:8080/api/jobexecutions/1/abandon" # to schedule a job execution with initial delay of 1 minute and repeating with 60-minute interval curl -s -X POST -H 'Content-Type:application/json' -d '{"jobName":"numbers", "initialDelay":1, "interval":60}' "http://localhost:8080/api/jobs/numbers/schedule" | jq # to list all job schedules curl -s "http://localhost:8080/api/schedules" | jq # to cancel a job schedule curl -s -X POST -H 'Content-Type:application/json' "http://localhost:8080/api/schedules/1/cancel" | jq # to get details of a job schedule curl -s "http://localhost:8080/api/schedules/2" | jq&lt;/pre&gt;&lt;!--[CodeBlockEnd:baf5b618-0945-47e4-bb3b-152e02323365]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;In above commands, a utility program called jq is used to pretty-print the JSON output. Its usage here is equivalent to "python -m json.tool".&amp;#160; To shut down the application, press Ctrl-C in the terminal window of the running application.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Also worth mentioning is Thorntail &lt;a class="jive-link-external-small" href="http://wildfly-swarm.io/generator/" rel="nofollow"&gt;Project Generator&lt;/a&gt;, which can be used to create the scaffold of your application.&amp;#160; It allows you to pick and choose which technologies and frameworks to use, and generates the required maven dependencies and plugins, and key application classes.&amp;#160; This comes handy for quickly starting new Thorntail-based development projects.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Build and Deploy Thorntail-based Batch Application to OpenShift Online&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Next let's look at how to build and deploy the same batch application to OpenShift.&amp;#160; OpenShift will need to enlist a Java SE runtime, and here we choose to use openjdk18.&amp;#160; All the operations we will be performing can be done via either OpenShift command line tool (oc), or OpenShift Web Console.&amp;#160; For the sake of brevity, we will use oc commands.&amp;#160; For introduction to various features in OpenShift, you may want to check out &lt;a class="jive-link-external-small" href="https://learn.openshift.com/" rel="nofollow"&gt;OpenShift interactive tutorials&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We assume you already have an OpenShift account, and to log in:&lt;/p&gt;&lt;!--[CodeBlockStart:0d34383f-6b6f-43dc-9fd9-4c8c5fbbdc6b][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc login https:xxx.openshift.com --token=xxx&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:0d34383f-6b6f-43dc-9fd9-4c8c5fbbdc6b]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To create a new project, if there is no existing projects:&lt;/p&gt;&lt;!--[CodeBlockStart:3f44cab3-c41c-4077-922e-2fd1b4efd65f][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc new-project&amp;#160;&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:3f44cab3-c41c-4077-922e-2fd1b4efd65f]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We wil use openjdk18-openshift image stream. Check if it is available in the current project:&lt;/p&gt;&lt;!--[CodeBlockStart:ad4dc06c-46db-4cd9-9198-1a53948716c2][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc get is&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:ad4dc06c-46db-4cd9-9198-1a53948716c2]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;If openjdk18-openshift is not present, import it:&lt;/p&gt;&lt;!--[CodeBlockStart:8e68c1ff-eb4a-46a3-b5f4-c95ab2419d2c][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc import-image my-redhat-openjdk-18/openjdk18-openshift --from=registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift --confirm&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:8e68c1ff-eb4a-46a3-b5f4-c95ab2419d2c]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To create a new application (with default name):&lt;/p&gt;&lt;!--[CodeBlockStart:349f7207-d248-4506-a443-3a0f3e2f9dd9][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc new-app openjdk18-openshift~https://github.com/jberet/numbers-chunk-thorntail.git&amp;#160; &lt;/pre&gt;&lt;!--[CodeBlockEnd:349f7207-d248-4506-a443-3a0f3e2f9dd9]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The above command will take a few minutes to complete, and to watch its status, run the following command:&lt;/p&gt;&lt;!--[CodeBlockStart:cbd91ad9-290f-4ef5-a61d-053643437bd0][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc rollout status dc/numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:cbd91ad9-290f-4ef5-a61d-053643437bd0]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To expose `numbers-chunk-thorntail` application to external clients, run the command:&lt;/p&gt;&lt;!--[CodeBlockStart:057b60d5-191d-4200-ae1a-bfea6b4882b1][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc expose svc numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:057b60d5-191d-4200-ae1a-bfea6b4882b1]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;The above command exposes our batch application service to external client, by creating a route.&amp;#160; To get the route information, filtering by label -l option:&lt;/p&gt;&lt;!--[CodeBlockStart:278cdfb8-19a1-4bd6-892e-0df3d19d7dcb][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc get route -l app=numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:278cdfb8-19a1-4bd6-892e-0df3d19d7dcb]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=";"&gt;NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;HOST/PORT&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;PATH &lt;/td&gt;&lt;td style=";"&gt;SERVICES&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;PORT&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;TERMINATION&amp;#160;&amp;#160; WILDCARD&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail&amp;#160;&amp;#160; numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;numbers-chunk-thorntail&amp;#160;&amp;#160; 8080-tcp&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;None&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Scale Thorntail-based Batch Application on OpenShift&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OpenShift makes it very easy to scale up and down your deployments, through either command line or web console.&amp;#160; Let's first check what pods are running the batch application:&lt;/p&gt;&lt;!--[CodeBlockStart:872c7d55-9839-4a3e-ab6d-39b453b418f5][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc get pod -l app=numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:872c7d55-9839-4a3e-ab6d-39b453b418f5]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=";"&gt;NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;READY&lt;/td&gt;&lt;td style=";"&gt;STATUS&lt;/td&gt;&lt;td style=";"&gt;RESTARTS&amp;#160;&amp;#160; AGE&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-nqnjj&amp;#160;&amp;#160; 1/1&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;2d&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;To view the application runtimne log in an text editor:&lt;/p&gt;&lt;!--[CodeBlockStart:802a4515-c1f7-4b77-95c2-f668902abdfb][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc logs numbers-chunk-thorntail-1-nqnjj | view -&lt;/pre&gt;&lt;!--[CodeBlockEnd:802a4515-c1f7-4b77-95c2-f668902abdfb]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;From the above log output, you can see that the application has been successfully built and deployed to OpenShift online, and the batch job has been started and completed.&amp;#160; As you can see, there is only 1 pod running this batch application.&amp;#160; To scale it up to 3 pods to service heavy load, and check the number of pods:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:d512cda9-de00-435d-9728-93b5cbaa875b][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc scale --replicas=3 dc numbers-chunk-thorntail deploymentconfig.apps.openshift.io "numbers-chunk-thorntail" scaled oc get pod -l app=numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:d512cda9-de00-435d-9728-93b5cbaa875b]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=";"&gt;NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;READY &lt;/td&gt;&lt;td style=";"&gt;STATUS&lt;/td&gt;&lt;td style=";"&gt;RESTARTS&amp;#160;&amp;#160; AGE&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-knxp7&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;29s&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-nqnjj&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;2d&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-vlcpt&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;29s&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Among the 3 pods listed above, we can see that 2 are newly started, along with the one that has been running for a while.&amp;#160; Now let's check how to scale it back.&amp;#160; Say, we want to scale it back to 2 if the current replica count is 3:&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:bef244a9-f389-4ca0-856e-83e3b1db7d8e][excluded]--&gt;&lt;pre class="plain" name="code"&gt;oc scale --current-replicas=3 --replicas=2 dc numbers-chunk-thorntail deploymentconfig.apps.openshift.io "numbers-chunk-thorntail" scaled oc get pod -l app=numbers-chunk-thorntail&lt;/pre&gt;&lt;!--[CodeBlockEnd:bef244a9-f389-4ca0-856e-83e3b1db7d8e]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style=";"&gt;NAME&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;READY &lt;/td&gt;&lt;td style=";"&gt;STATUS&lt;/td&gt;&lt;td style=";"&gt;RESTARTS&amp;#160;&amp;#160; AGE&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-knxp7&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;11m&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=";"&gt;numbers-chunk-thorntail-1-nqnjj&amp;#160;&amp;#160; 1/1&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;Running&amp;#160;&amp;#160; 0&amp;#160;&amp;#160;&amp;#160;&amp;#160;&amp;#160; &lt;/td&gt;&lt;td style=";"&gt;2d&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Access Thorntail-based Batch Application on OpenShift through REST API&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Once the application is deployed to OpenShift, you can invokes its REST API to perform various batch processing operations. The steps are the same for both local Thorntail or OpenShift Thorntail runtime. &lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;!--[CodeBlockStart:f524f416-5643-4b65-96b6-7a021b96439f][excluded]--&gt;&lt;pre class="plain" name="code"&gt;# to start the job named `numbers` curl -s -X POST -H 'Content-Type:application/json' "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/jobs/numbers/start" | jq # to get the details and status of the newly started job execution curl -s "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/jobexecutions/1" | jq # to get all step executions belonging to this job execution curl -s "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/jobexecutions/1/stepexecutions" | jq # to abandon the above job execution curl -X POST -H 'Content-Type:application/json' "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/jobexecutions/1/abandon" # to schedule a job execution with initial delay of 1 minute and repeating with 60-minute interval curl -s -X POST -H 'Content-Type:application/json' -d '{"jobName":"numbers", "initialDelay":1, "interval":60}' "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/jobs/numbers/schedule" | jq # to list all job schedules curl -s "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/schedules" | jq # to cancel a job schedule curl -s -X POST -H 'Content-Type:application/json' "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/schedules/1/cancel" | jq # to get details of a job schedule curl -s "http://numbers-chunk-thorntail-pr.xxxx.xxxx.openshiftapps.com/api/schedules/2" | jq&lt;/pre&gt;&lt;!--[CodeBlockEnd:f524f416-5643-4b65-96b6-7a021b96439f]--&gt;&lt;div style="display:none;"&gt;&lt;/div&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h2&gt;Summary&lt;/h2&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;We've just finished developing, deploying and running a batch processing microservices application based on Thorntail, in both local environment and OpenShift Online.&amp;#160; The combined power of Thorntail MicroProfile and OpenShift has opened up many possibilities for developing and managing batch processing applications.&amp;#160; I hope you find the information presented here useful, and as always, feedback and comments are much appreciated.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:676756fe-8f94-4704-a5e2-552ba939c820] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Fg8Orfw7l9U" height="1" width="1" alt=""/&gt;</content><summary>Introduction   This blog post is the part of the series that showcase some of the work in JBeret family projects for modernizing Java batch processing.  Previously, we've discussed how to move your batch processing workload developed for Java SE standalone environment (see this post) and Java EE platform (see this post) to PaaS such as OpenShift.  They serve as good proof that standard-based batch...</summary><dc:creator>Cheng Fang</dc:creator><dc:date>2018-10-02T03:43:55Z</dc:date><feedburner:origLink>https://developer.jboss.org/community/jberet/blog/2018/10/01/microservices-batch-application-with-thorntail-and-openshift</feedburner:origLink></entry><entry><title>Patterns for distributed transactions within a microservices architecture</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/GhWENUizMsY/" /><category term="Microservices" /><category term="Modern App Dev" /><category term="2pc" /><category term="App Dev" /><category term="architecture" /><category term="Design Patterns" /><category term="enterprise architecture" /><category term="microservices" /><category term="pattern" /><category term="Saga pattern" /><category term="two-phase commit" /><author><name>Keyang Xiang</name></author><id>https://developers.redhat.com/blog/?p=520997</id><updated>2018-10-01T20:05:00Z</updated><published>2018-10-01T20:05:00Z</published><content type="html">&lt;p&gt;&lt;img class=" alignright wp-image-522177 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/APP_DEV_CoE_reverse-1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/APP_DEV_CoE_reverse-1.png" alt="Red Hat Application Development Center of Excellence Logo" width="322" height="110" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/APP_DEV_CoE_reverse-1.png 322w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/APP_DEV_CoE_reverse-1-300x102.png 300w" sizes="(max-width: 322px) 100vw, 322px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices/"&gt;Microservices&lt;/a&gt; architecture (MSA) has become very popular.. However, one common problem is how to manage distributed transactions across multiple microservices. This post is going to share my experience from past projects and explain the problem and possible patterns that could solve it.&lt;/p&gt; &lt;h2&gt;What is a distributed transaction?&lt;/h2&gt; &lt;p&gt;When a microservice architecture decomposes a monolithic system into self-encapsulated services, it can break transactions. This means a &lt;strong&gt;local transaction &lt;/strong&gt;in the monolithic system is now &lt;strong&gt;distributed &lt;/strong&gt;into multiple services that will be called in a sequence.&lt;span id="more-520997"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Here is a customer order example with a monolithic system using a local transaction:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-4.png"&gt;&lt;img class=" alignright wp-image-521067 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-4.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-4.png" alt="Diagram of customer order example with a monolithic system using a local transaction" width="475" height="551" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-4.png 475w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-4-259x300.png 259w" sizes="(max-width: 475px) 100vw, 475px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the customer order example above, if a user sends a &lt;strong&gt;Put Order &lt;/strong&gt;action to a monolithic system, the system will create a  local database transaction that works over multiple database tables. If any step fails, the transaction can &lt;strong&gt;roll back&lt;/strong&gt;. This is known as ACID (Atomicity, Consistency, Isolation, Durability), which is guaranteed by the database system.&lt;/p&gt; &lt;p&gt;When we decompose this system, we created both the &lt;code&gt;CustomerMicroservice&lt;/code&gt;and the &lt;code&gt;OrderMicroservice&lt;/code&gt;&lt;strong&gt;,&lt;/strong&gt; which have separate databases. Here is a customer order example with microservices:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5.png"&gt;&lt;img class=" alignright wp-image-521087 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5.png" alt="Diagram of customer order example with microservices" width="783" height="463" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5.png 783w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5-300x177.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-5-768x454.png 768w" sizes="(max-width: 783px) 100vw, 783px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When a &lt;strong&gt;Put Order&lt;/strong&gt; request comes from the user, both microservices will be called to apply changes into their own database. Because the transaction is now across multiple databases, it is now considered a &lt;strong&gt;distributed transaction&lt;/strong&gt;.&lt;/p&gt; &lt;h2&gt;What is the problem?&lt;/h2&gt; &lt;p&gt;In a monolithic system, we have a database system to ensure ACIDity. We now need to clarify the following key problems.&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;How do we keep the transaction atomic?&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;In a database system, atomicity means that in a transaction either &lt;strong&gt;all steps complete&lt;/strong&gt; or &lt;strong&gt;no steps complete. &lt;/strong&gt;The microservice-based system does not have a global transaction coordinator by default. In the example above, if the &lt;code&gt;CreateOrder&lt;/code&gt; method fails, how do we roll back the changes we applied by the &lt;code&gt;CustomerMicroservice&lt;/code&gt;&lt;strong&gt;? &lt;/strong&gt;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;Do we isolate user actions for concurrent requests?&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;If an object is written by a transaction and at the same time (before the transaction ends), it is read by another request, should the object return old data or updated data? In the example above, once &lt;code&gt;UpdateCustomerFund&lt;/code&gt; succeeds but is still waiting for a response from &lt;code&gt;CreateOrder&lt;/code&gt;, should requests for the current customer&amp;#8217;s fund return the updated amount or not?&lt;/p&gt; &lt;h2&gt;Possible solutions&lt;/h2&gt; &lt;p&gt;The problems above are important for microservice-based systems. Otherwise, there is no way to tell if a transaction has completed successfully. The following two patterns can resolve the problem:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;2pc (two-phase commit)&lt;/li&gt; &lt;li&gt;Saga&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Two-phase commit (2pc) pattern&lt;/h3&gt; &lt;p&gt;2pc is widely used in database systems. For some situations, you can use 2pc for microservices. Just be careful; not all situations suit 2pc and, in fact, 2pc is considered impractical within a microservice architecture (explained below).&lt;/p&gt; &lt;p&gt;So what is a two-phase commit?&lt;/p&gt; &lt;p&gt;As its name hints, 2pc has two phases: A &lt;em&gt;prepare phase&lt;/em&gt; and a &lt;em&gt;commit phase&lt;/em&gt;. In the prepare phase, all microservices will be asked to prepare for some data change that could be done atomically. Once all microservices are prepared, the commit phase will ask all the microservices to make the actual changes.&lt;/p&gt; &lt;p&gt;Normally, there needs to be a global coordinator to maintain the lifecycle of the transaction, and the coordinator will need to call the microservices in the prepare and commit phases.&lt;/p&gt; &lt;p&gt;Here is a 2pc implementation for the customer order example:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-6.png"&gt;&lt;img class=" alignright wp-image-521477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-6.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-6.png" alt="Diagram of 2pc implementation for the customer order example" width="544" height="414" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-6.png 544w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-6-300x228.png 300w" sizes="(max-width: 544px) 100vw, 544px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the example above, when a user sends a put order request, the &lt;code&gt;Coordinator&lt;/code&gt; will first create a global transaction with all the context information. It will then tell &lt;code&gt;CustomerMicroservice&lt;/code&gt; to prepare for updating a customer fund with the created transaction. The &lt;code&gt;CustomerMicroservice&lt;/code&gt; will then check, for example, if the customer has enough funds to proceed with the transaction. Once &lt;code&gt;CustomerMicroservice&lt;/code&gt; is OK to perform the change, it will lock down the object from further changes and tell the &lt;code&gt;Coordinator&lt;/code&gt; that it is prepared. The same thing happens while creating the order in the &lt;code&gt;OrderMicroservice&lt;/code&gt;. Once the &lt;code&gt;Coordinator&lt;/code&gt; has confirmed all microservices are ready to apply their changes, it will then ask them to apply their changes by requesting a commit with the transaction. At this point, all objects will be unlocked.&lt;/p&gt; &lt;p&gt;If at any point a single microservice fails to prepare, the &lt;code&gt;Coordinator&lt;/code&gt; will abort the transaction and begin the rollback process. Here is a diagram of a 2pc rollback for the customer order example:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-7.png"&gt;&lt;img class=" alignright wp-image-521497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-7.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-7.png" alt="Diagram of a 2pc rollback for the customer order example" width="543" height="356" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-7.png 543w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-7-300x197.png 300w" sizes="(max-width: 543px) 100vw, 543px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the above example, the &lt;code&gt;CustomerMicroservice&lt;/code&gt; failed to prepare for some reason, but the &lt;code&gt;OrderMicroservice&lt;/code&gt; has replied that it is prepared to create the order. The &lt;code&gt;Coordinator&lt;/code&gt; will request an abort on the &lt;code&gt;OrderMicroservice&lt;/code&gt; with the transaction and the &lt;code&gt;OrderMicroservice&lt;/code&gt; will then roll back any changes made and unlock the database objects.&lt;/p&gt; &lt;h4&gt;Benefits of using 2pc&lt;/h4&gt; &lt;p&gt;2pc is a very strong consistency protocol. First, the prepare and commit phases guarantee that the transaction is atomic. The transaction will end with either all microservices returning successfully or all microservices have nothing changed.  Secondly, 2pc allows read-write isolation. This means the changes on a field are not visible until the coordinator commits the changes.&lt;/p&gt; &lt;h4&gt;Disadvantages of using 2pc&lt;/h4&gt; &lt;p&gt;While 2pc has solved the problem, it is not really recommended for many microservice-based systems because 2pc is synchronous (blocking). The protocol will need to lock the object that will be changed before the transaction completes. In the example above, if a customer places an order, the &amp;#8220;fund&amp;#8221; field will be locked for the customer. This prevents the customer from applying new orders. This makes sense because if a &amp;#8220;prepared&amp;#8221; object changed after it claims it is &amp;#8220;prepared,&amp;#8221; then the commit phase could possibly not work.&lt;/p&gt; &lt;p&gt;This is not good. In a database system, transactions tend to be fast—normally within 50 ms. However, microservices have long delays with RPC calls, especially when integrating with external services such as a payment service. The lock could become a system performance bottleneck. Also, it is possible to have two transactions mutually lock each other (deadlock) when each transaction requests a lock on a resource the other requires.&lt;/p&gt; &lt;h3&gt;Saga pattern&lt;/h3&gt; &lt;p&gt;The Saga pattern is another widely used pattern for distributed transactions. It is different from 2pc, which is synchronous. The Saga pattern is asynchronous and reactive. In a Saga pattern, the distributed transaction is fulfilled by asynchronous local transactions on all related microservices. The microservices communicate with each other through an event bus.&lt;/p&gt; &lt;p&gt;Here is a diagram of the Saga pattern for the customer order example:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-8.png"&gt;&lt;img class=" alignright wp-image-521807 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-8.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-8.png" alt="Diagram of the Saga pattern for the customer order example" width="473" height="283" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-8.png 473w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-8-300x179.png 300w" sizes="(max-width: 473px) 100vw, 473px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the example above, the &lt;code&gt;OrderMicroservice&lt;/code&gt; receives a request to place an order. It first starts a local transaction to create an order and then emits an &lt;code&gt;OrderCreated&lt;/code&gt; event. The &lt;code&gt;CustomerMicroservice&lt;/code&gt; listens for this event and updates a customer fund once the event is received. If a deduction is successfully made from a fund, a &lt;code&gt;CustomerFundUpdated&lt;/code&gt; event will then be emitted, which in this example means the end of the transaction.&lt;/p&gt; &lt;p&gt;If any microservice fails to complete its local transaction, the other microservices will run compensation transactions to rollback the changes. Here is a diagram of the Saga pattern for a compensation transaction:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-9.png"&gt;&lt;img class=" alignright wp-image-521817 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-9.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-9.png" alt="Diagram of the Saga pattern for a compensation transaction" width="651" height="365" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-9.png 651w, https://developers.redhat.com/blog/wp-content/uploads/2018/09/Untitled-UML-9-300x168.png 300w" sizes="(max-width: 651px) 100vw, 651px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In the above example, the &lt;code&gt;UpdateCustomerFund&lt;/code&gt; failed for some reason and it then emitted a &lt;code&gt;CustomerFundUpdateFailed&lt;/code&gt; event. The &lt;code&gt;OrderMicroservice&lt;/code&gt; listens for the event and start its compensation transaction to revert the order that was created.&lt;/p&gt; &lt;h4&gt;Advantages of the Saga pattern&lt;/h4&gt; &lt;p&gt;One big advantage of the Saga pattern is its support for long-lived transactions. Because each microservice focuses only on its own local atomic transaction, other microservices are not blocked if a microservice is running for a long time. This also allows transactions to continue waiting for user input. Also, because all local transactions are happening in parallel, there is no lock on any object.&lt;/p&gt; &lt;h4&gt;Disadvantages of the Saga pattern&lt;/h4&gt; &lt;p&gt;The Saga pattern is difficult to debug, especially when many microservices are involved. Also, the event messages could become difficult to maintain if the system gets complex. Another disadvantage of the Saga pattern is it does not have read isolation. For example, the customer could see the order being created, but in the next second, the order is removed due to a compensation transaction.&lt;/p&gt; &lt;h4&gt;Adding a process manager&lt;/h4&gt; &lt;p&gt;To address the complexity issue of the Saga pattern, it is quite normal to add a process manager as an orchestrator. The process manager is responsible for listening to events and triggering endpoints.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The Saga pattern is a preferable way of solving distributed transaction problems for a microservice-based architecture. However, it also introduces a new set of problems, such as how to atomically update the database and emit an event. Adoption of the Saga pattern requires a change in mindset for both development and testing. It could be a challenge for a team that is not familiar with this pattern. There are many variants that simplify its implementation. Therefore, it is important to choose the proper way to implement it for a project.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;linkname=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F01%2Fpatterns-for-distributed-transactions-within-a-microservices-architecture%2F&amp;#38;title=Patterns%20for%20distributed%20transactions%20within%20a%20microservices%20architecture" data-a2a-url="https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture/" data-a2a-title="Patterns for distributed transactions within a microservices architecture"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture/"&gt;Patterns for distributed transactions within a microservices architecture&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/GhWENUizMsY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Microservices architecture (MSA) has become very popular.. However, one common problem is how to manage distributed transactions across multiple microservices. This post is going to share my experience from past projects and explain the problem and possible patterns that could solve it. What is a distributed transaction? When a microservice architecture decomposes a monolithic system into self-encapsulated [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture/"&gt;Patterns for distributed transactions within a microservices architecture&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">520997</post-id><dc:creator>Keyang Xiang</dc:creator><dc:date>2018-10-01T20:05:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/01/patterns-for-distributed-transactions-within-a-microservices-architecture/</feedburner:origLink></entry><entry><title>The Cathedral and the Bazaar: Moving from Barter to a Currency System</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/SBHmDWygm6Q/the-cathedral-and-bazaar-moving-from.html" /><category term="Blockchain" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_ofbizian" scheme="searchisko:content:tags" /><category term="open source" scheme="searchisko:content:tags" /><author><name>Bilgin Ibryam</name></author><id>searchisko:content:id:jbossorg_blog-the_cathedral_and_the_bazaar_moving_from_barter_to_a_currency_system</id><updated>2018-10-01T11:46:59Z</updated><published>2018-10-01T11:43:00Z</published><content type="html">&lt;span style="font-family: inherit;"&gt;&lt;i&gt;This post was originally published as "How blockchain can complement open source" on &lt;a href="https://opensource.com/article/18/9/barter-currency-system" target="_blank"&gt;Opensource.com&lt;/a&gt; under CC BY-SA 4.0. &lt;/i&gt;&lt;/span&gt;&lt;i&gt;If you prefer, you can also read the same post on &lt;a href="https://medium.com/@bibryam/the-cathedral-and-the-bazaar-moving-from-barter-to-a-currency-system-4f83c0fd8bb4" target="_blank"&gt;Medium&lt;/a&gt;. &lt;/i&gt;&lt;br /&gt;&lt;h3&gt;Open Won Over Closed&lt;/h3&gt;&lt;a href="http://catb.org/"&gt;The Cathedral and The Bazaar&lt;/a&gt; is the classic open source story written 20 years ago by Eric Steven Raymond. In the story, Eric describes a new revolutionary software development model where complex software projects are built without (or with a very little) central management. This new model is open source. Eric's story compares two models:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The classic model (represented by the cathedral) where software is crafted by a small group of individuals in a closed and controlled environment through slow and stable releases.&lt;/li&gt;&lt;li&gt;And the new model (represented by the bazaar) where software is crafted in an open environment where individuals can participate freely, but still produce a stable and coherent system.&lt;/li&gt;&lt;/ul&gt;Some of the reasons for open source being so successful can be traced back to the founding principles described by Eric. Releasing early, releasing often, accepting the fact that many heads are inevitably better than one allows open source projects to tap into the world's pool of talent (and not many companies can match that using the closed source model).&lt;br /&gt;&lt;br /&gt;Two decades after Eric's reflective analysis of the hacker community, we see open source becoming dominant. It is not any longer a model only for scratching a developer’s personal itch, but instead, the place where innovation happens. It is the model that even worlds&lt;a href="http://oss.cash/"&gt; largest&lt;/a&gt; software companies are transitioning to in order to continue dominating.&lt;br /&gt;&lt;h3&gt;A Barter System&lt;/h3&gt;If we look closely at how the open source model works in practice, we realize that it is a closed system exclusive only to open source developers and techies. The only way to influence the direction of a project is by joining the open source community, understanding the written and the unwritten rules, learning how to contribute, the coding standards, etc, and doing it yourself. This is how the bazaar works and where the barter system analogy comes from. A barter system is a method of exchange of services and goods for other services and goods in return. In the bazaar - where the software is built, that means, in order to take something, you have to be also a producer yourself, and give something back in return. And that is, by exchanging your time and knowledge for getting something done. A bazaar is a place where open source developers interact with other open source developers and produce open source software, the open source way.&lt;br /&gt;&lt;br /&gt;The barter system is a great step forward and an evolution from the state of self-sufficiency where everybody has to be a jack of all trades. The bazaar (open source model) using the barter system allows people with common interests and different skills to gather, collaborate and create something that no individual can create on their own. The barter system is simple and lacks complex problems of the modern monetary systems, but it also has some limitations to name a few:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Lack of divisibility - in the absence of a common medium of exchange, a large indivisible commodity/value cannot be exchanged for a smaller commodity/value. For example, even if you want to do a small change in an open source project, you may still have to go through a high entry barrier sometimes.&lt;/li&gt;&lt;li&gt;Storing value - if a project is important to your company, you may want to have a large investment/commitment in it. But since it is a barter system among open source developers, the only way to have a strong say is by employing many open source committers and that is not always possible.&lt;/li&gt;&lt;li&gt;Transferring value - if you have invested in a project (trained employees, hired open source developers) and want to move focus to another project, it is not possible to transfer expertise, reputation, influence quickly.&lt;/li&gt;&lt;li&gt;Temporal decoupling - the barter system does not provide a good mechanism for deferred or in advance commitments. In the open source world, that means a user cannot express its commitment/interest in a project in a measurable way in advance, or continuously for future periods.&lt;/li&gt;&lt;/ul&gt;We will see below what is the back door to the bazaar and how to address these limitations.&lt;br /&gt;&lt;h3&gt;A Currency System&lt;/h3&gt;People are hanging at the bazaar for different reasons: some are there to learn, some are there to scratch a developer’s personal itch and some work for large software farms. And since the only way to have a say in the bazaar is by becoming part of the open source community and joining the barter system, in order to gain credibility in the open source world, many large software companies pay these developers in a monetary value and employ them. The latter represents the use of a currency system to influence the bazaar. Open source is not any longer for scratching the personal developer itch only. It also accounts for a significant part of the overall software production worldwide and there are many who want to have an influence.&lt;br /&gt;&lt;br /&gt;Open source sets the guiding principles through which developers interact and build a coherent system in a distributed way. It dictates how a project is governed, software is built and the output distributed to users. It is an open consensus model for decentralized entities for building quality software together. But the open source model does not cover how open source is subsidized. Whether it is sponsored, directly or indirectly, through intrinsic or extrinsic motivators is irrelevant to the bazaar.&lt;br /&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-5_yDt3OqI3Y/W4LtWzFkPXI/AAAAAAAALWY/nGTjXySgmEsc8ZEUvb8MkdGzjHsXiXNugCLcBGAs/s1600/Tokenomics%2B-%2BPage%2B4%25281%2529.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="1193" data-original-width="1600" height="475" src="https://1.bp.blogspot.com/-5_yDt3OqI3Y/W4LtWzFkPXI/AAAAAAAALWY/nGTjXySgmEsc8ZEUvb8MkdGzjHsXiXNugCLcBGAs/s640/Tokenomics%2B-%2BPage%2B4%25281%2529.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;div dir="ltr" id="docs-internal-guid-19ce7356-7fff-5fe9-f057-4b2c3af0d568" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;"&gt;&lt;i&gt;Centralized and decentralized ecosystems supporting open source&lt;/i&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br /&gt;Currently, there is no equivalent of the decentralized open source development model for subsidization purpose. The majority of the open source subsidization is centralized and monopolized typically by one company which dominates a project by employing the majority of the open source developers of that project. And to be honest, this is currently the best case scenario which guarantees that the developers will be employed and the project will continue flourishing. While a company is working on its paid software or services whether that is SaaS subsodizes open source development indirectly.&lt;br /&gt;&lt;br /&gt;There are also exceptions for the project monopoly scenario: for example, some of the Cloud Native Computing Foundation projects are developed by a large number of competing companies. Also, the Apache Software Foundation aims for their projects not to be dominated by a single vendor by encouraging diverse contributors, but most of the popular projects, in reality, are still single vendor projects...&lt;br /&gt;&lt;br /&gt;What we are still missing is an open and decentralized model that works like the bazaar without a central coordination and ownership, where consumers (open source users) and producers (open source developers) interact with each other driven by market forces and open source value. In order to complement open source, such a model also has to be open and decentralized and this is why the blockchain technology would&lt;a href="https://opensource.com/article/18/8/open-source-tokenomics"&gt; fit here best&lt;/a&gt;. This would create an complementary ecosystem that flows subsidies from users to developers, but without a centralized and monopolized entity (such as an open source company). There are already successful open source cryptocurrency projects such as&lt;a href="https://www.decred.org/"&gt; Decred&lt;/a&gt;,&lt;a href="https://www.dash.org/"&gt; Dash&lt;/a&gt;,&lt;a href="https://getmonero.org/"&gt; Monero&lt;/a&gt;,&lt;a href="https://z.cash/"&gt; Zcash&lt;/a&gt;, that use a similar&lt;a href="https://nadiaeghbal.com/grant-programs"&gt; decentralized funding model&lt;/a&gt; where a portion of the mining or donations subsidy is used for their own development.&lt;br /&gt;&lt;br /&gt;Most of the existing platforms (blockchain or non-blockchain) that aim to subsidize open source development are targeting primarily bug bounties, small and piecemeal tasks. There are also a few focused on the funding of new open source projects. But there are not many that aim to provide mechanisms for sustaining continued development of open source projects. Basically, a system that would emulate the behavior of an open source service provider company, or open core, open source based SaaS product company: ensuring developers get continued and predictable incentives, and guiding the project development based on the priorities of the incentivizers, i.e. the users. Such a model would address the limitations of the barter system listed above:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Allow divisibility - if you want something small fixed, you can pay a small amount without paying the full premium of becoming an open source developer for a project.&lt;/li&gt;&lt;li&gt;Storing value - you can invest a large amount into a project and ensure its continued development and ensure your voice is heard.&lt;/li&gt;&lt;li&gt;Transferring value - at any point, you can stop investing in the project and move funds into other projects.&lt;/li&gt;&lt;li&gt;Temporal decoupling - allow regular recurring payments and subscriptions.&lt;/li&gt;&lt;/ul&gt;There would be also other benefits raising purely from the fact that such a blockchain based system is transparent and decentralized: to quantify a project's value/usefulness based on its users' commitment, decentralized roadmap governance, decentralized decision making, etc. While there still will be user who prefer to use the more centrally managed software, there will be others who prefer the more transparent and decentralized way of influencing projects. There is enough room for all parties.&lt;br /&gt;&lt;h3&gt;Conclusion&lt;/h3&gt;On the one hand, we see large companies hiring open source developers, and acquiring open source startups and even foundational platforms (such as Microsoft buying Github). Many if not most long-running successful open source projects are centralised around a single vendor. The significance of open source, and its centralisation is a fact.&lt;br /&gt;&lt;br /&gt;On the other hand, the challenges around&lt;a href="https://www.youtube.com/watch?v=VS6IpvTWwkQ"&gt; sustaining open source&lt;/a&gt; software are becoming more apparent, and there are many investigating deeper this space and its foundational issues. There are a few projects with high visibility and a large number of contributors, but there are also many other still important projects but with not enough contributors and maintainers.&lt;br /&gt;&lt;br /&gt;There are&lt;a href="https://opensource.com/article/18/8/open-source-tokenomics"&gt; many efforts&lt;/a&gt; trying to address the challenges of open source through blockchain. These projects should improve the transparency, decentralization, subsidization, and establish a direct link between open source users and developers. This space is still very young but progressing fast, and with time, the bazaar is going to have a cryptocurrency system.&lt;br /&gt;&lt;br /&gt;Given enough time, and adequate technology, decentralization is happening at many levels:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;The Internet is a decentralised medium that unlocked world's potential for sharing and acquiring knowledge.&lt;/li&gt;&lt;li&gt;Open source is a decentralized collaboration model that unlocked the world's potential for innovation.&lt;/li&gt;&lt;li&gt;And similarly, blockchain can complement open source and become the decentralized open source subsidization model.&lt;/li&gt;&lt;/ul&gt;Follow me on &lt;a href="http://twitter.com/bibryam"&gt;twitter&lt;/a&gt; for other posts in this space.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/SBHmDWygm6Q" height="1" width="1" alt=""/&gt;</content><summary>This post was originally published as "How blockchain can complement open source" on Opensource.com under CC BY-SA 4.0. If you prefer, you can also read the same post on Medium. Open Won Over ClosedThe Cathedral and The Bazaar is the classic open source story written 20 years ago by Eric Steven Raymond. In the story, Eric describes a new revolutionary software development model where complex softw...</summary><dc:creator>Bilgin Ibryam</dc:creator><dc:date>2018-10-01T11:43:00Z</dc:date><feedburner:origLink>http://www.ofbizian.com/2018/10/the-cathedral-and-bazaar-moving-from.html</feedburner:origLink></entry></feed>
